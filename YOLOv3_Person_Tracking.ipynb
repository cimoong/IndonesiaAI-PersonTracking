{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOECY9daOao5"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1fpLwBOOTOD",
        "outputId": "b1d2a147-3d96-4746-dfd5-1c9bea3d2e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.21.0-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.26.151-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.0)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Collecting Deprecated (from fiftyone)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting eventlet (from fiftyone)\n",
            "  Downloading eventlet-0.33.3-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.18.3)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading Hypercorn-0.14.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.2)\n",
            "Collecting kaleido (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.1.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (23.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (8.4.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.13.1)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.7.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2022.10.31)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting starlette<0.27,>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.8.10)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting fiftyone-brain<0.13,>=0.12 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.12.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fiftyone-db<0.5,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting voxel51-eta<0.11,>=0.10 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.10.0-py2.py3-none-any.whl (568 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.9/568.9 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0.72)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from fiftyone-brain<0.13,>=0.12->fiftyone) (1.10.1)\n",
            "Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (2.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.2.2)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.27,>=0.24.0->fiftyone) (3.6.2)\n",
            "Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading py7zr-0.20.5-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile (from voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (4.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.11,>=0.10->fiftyone) (1.26.15)\n",
            "Collecting botocore<1.30.0,>=1.29.151 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.29.151-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.10/dist-packages (from eventlet->fiftyone) (2.0.2)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.27,>=0.24.0->fiftyone) (1.3.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.11,>=0.10->fiftyone) (23.1.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting pycryptodomex>=3.6.6 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzstd>=0.14.4 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pyzstd-0.15.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.3/399.3 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppmd<1.1.0,>=0.18.1 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pyppmd-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybcj>=0.6.0 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading pybcj-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Collecting brotli>=1.0.9 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting inflate64>=0.3.1 (from py7zr->voxel51-eta<0.11,>=0.10->fiftyone)\n",
            "  Downloading inflate64-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.11,>=0.10->fiftyone) (2.0.12)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal->voxel51-eta<0.11,>=0.10->fiftyone) (0.1.0.post0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal->voxel51-eta<0.11,>=0.10->fiftyone) (2023.3)\n",
            "Installing collected packages: texttable, sseclient-py, rarfile, pprintpp, kaleido, brotli, xmltodict, retrying, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, eventlet, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n",
            "Successfully installed Deprecated-1.2.14 aiofiles-23.1.0 argcomplete-3.1.0 boto3-1.26.151 botocore-1.29.151 brotli-1.0.9 dacite-1.7.0 dill-0.3.6 dnspython-2.3.0 eventlet-0.33.3 fiftyone-0.21.0 fiftyone-brain-0.12.0 fiftyone-db-0.4.0 ftfy-6.1.1 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.17.2 httpx-0.24.1 hypercorn-0.14.3 hyperframe-6.0.1 inflate64-0.3.1 jmespath-1.0.1 jsonlines-3.1.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.1.2 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.20.5 pybcj-1.0.1 pycryptodomex-3.18.0 pymongo-4.3.3 pyppmd-1.0.0 pyzstd-0.15.7 rarfile-4.0 retrying-1.3.4 s3transfer-0.6.1 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.26.1 strawberry-graphql-0.138.1 texttable-1.6.7 universal-analytics-python3-1.1.1 voxel51-eta-0.10.0 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id9nft29OfB8",
        "outputId": "fcfff7b4-419a-46bf-ab2f-13bb9330e033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.21.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [8.2s elapsed, 0s remaining, 255.9Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [8.2s elapsed, 0s remaining, 255.9Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 3000 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 3000 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |████████████████| 3000/3000 [12.7m elapsed, 0s remaining, 4.1 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |████████████████| 3000/3000 [12.7m elapsed, 0s remaining, 4.1 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 3000 downloaded samples to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 3000/3000 [24.1s elapsed, 0s remaining, 121.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 3000/3000 [24.1s elapsed, 0s remaining, 121.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-train-3000' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train-3000' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 500 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading 500 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████████████████| 500/500 [2.1m elapsed, 0s remaining, 3.9 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████████████████| 500/500 [2.1m elapsed, 0s remaining, 3.9 images/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations for 500 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 500/500 [3.5s elapsed, 0s remaining, 136.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 500/500 [3.5s elapsed, 0s remaining, 136.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation-500' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        coco-2017-train-3000\n",
            "Media type:  image\n",
            "Num samples: 3000\n",
            "Persistent:  False\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Load the COCO-2017 dataset\n",
        "# This will download it from the FiftyOne Dataset Zoo if necessary\n",
        "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"train\", label_types=[\"detections\"], classes=[\"person\"], max_samples=3000)\n",
        "dataset_test = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\", label_types=[\"detections\"], classes=[\"person\"], max_samples=500)\n",
        "\n",
        "# Print summary information about the view\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O85XXHAva7ju",
        "outputId": "7f0011b0-dbe8-4608-c022-9dd76752c43c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2jT-yTvtOgdF"
      },
      "outputs": [],
      "source": [
        "# Iterate over the dataset\n",
        "for sample in dataset:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qTCfXbTUOhrl"
      },
      "outputs": [],
      "source": [
        "# Iterate over the dataset\n",
        "for sample in dataset_test:\n",
        "    # Get the detections\n",
        "    detections = sample.ground_truth.detections\n",
        "    # Filter out non-person detections\n",
        "    detections = [d for d in detections if d.label == \"person\"]\n",
        "    # Update the detections\n",
        "    sample.ground_truth.detections = detections\n",
        "    # Save the sample\n",
        "    sample.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpELFe14ZhWi"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8UYIF1RkEt8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a731a015-37ef-406e-a42f-a658b810f87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 08:09:29--  https://raw.githubusercontent.com/IndonesiaAI/yolov3-utils/main/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12325 (12K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  12.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-11 08:09:29 (83.6 MB/s) - ‘utils.py’ saved [12325/12325]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/IndonesiaAI/yolov3-utils/main/utils.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "x1p8sm0laYDn"
      },
      "outputs": [],
      "source": [
        "from utils import non_max_suppression, plot_image, mean_average_precision, get_evaluation_bboxes, cells_to_bboxes, intersection_over_union"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-jqxMz-Q9jE"
      },
      "source": [
        "## Datasets Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AeYJ-qJdei2B"
      },
      "outputs": [],
      "source": [
        "ANCHORS = [\n",
        "    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],\n",
        "    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],\n",
        "    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],\n",
        "]  # Note these have been rescaled to be between [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bm7X1wkxOjR8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def iou_width_height(boxes1, boxes2): #Iou untuk menghitung anchor\n",
        "    intersection = torch.min(boxes1[..., 0], boxes2[..., 0]) * torch.min(\n",
        "        boxes1[..., 1], boxes2[..., 1]\n",
        "    )\n",
        "    union = (\n",
        "        boxes1[..., 0] * boxes1[..., 1] + boxes2[..., 0] * boxes2[..., 1] - intersection\n",
        "    )\n",
        "    return intersection / union\n",
        "\n",
        "class CocoPersonDataset(Dataset):\n",
        "    def __init__(self, coco_dataset, anchors=ANCHORS, S=[13, 26, 52], transforms=None):\n",
        "        self.coco_dataset = coco_dataset\n",
        "        self.person_category_id = 0  # Person category ID in COCO dataset\n",
        "\n",
        "        # Save sample IDs\n",
        "        self.ids = [sample.id for sample in coco_dataset]\n",
        "\n",
        "        self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2])  # for all 3 scales\n",
        "        self.num_anchors = self.anchors.shape[0]\n",
        "        self.num_anchors_per_scale = self.num_anchors // 3\n",
        "        self.S = S\n",
        "        self.ignore_iou_thresh = 0.5\n",
        "\n",
        "        # Define data augmentation transforms\n",
        "        if transforms is None:\n",
        "            self.transforms = A.Compose([\n",
        "                A.Resize(height=416, width=416),\n",
        "                A.Normalize(),\n",
        "                ToTensorV2(),\n",
        "            ])\n",
        "        else:\n",
        "            self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.coco_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.ids[idx]\n",
        "        sample = self.coco_dataset[sample_id]\n",
        "\n",
        "        # Load image and annotations\n",
        "        image = Image.open(sample.filepath).convert('RGB')\n",
        "        image = np.array(image)\n",
        "        annotations = sample.ground_truth.detections\n",
        "\n",
        "        # Extract bounding boxes and convert to YOLO format\n",
        "        bboxes = []\n",
        "        for annotation in annotations:\n",
        "            bbox = annotation.bounding_box\n",
        "            x, y, width, height = bbox\n",
        "            xc = x + width / 2\n",
        "            yc = y + height / 2\n",
        "            w = width\n",
        "            h = height\n",
        "            bboxes.append([xc, yc, w, h, self.person_category_id])\n",
        "\n",
        "        # Apply data augmentation transforms\n",
        "        if self.transforms:\n",
        "          augmented = self.transforms(image=image)\n",
        "          image = augmented[\"image\"]\n",
        "\n",
        "        bboxes = torch.tensor(bboxes)\n",
        "\n",
        "        targets = [torch.zeros((self.num_anchors // 3, S, S, 6)) for S in self.S]\n",
        "\n",
        "        for box in bboxes:\n",
        "            iou_anchors = iou_width_height(torch.tensor(box[2:4]), self.anchors)\n",
        "            anchor_indices = iou_anchors.argsort(descending=True, dim=0) #diurutin dari iou yang paling besar untuk index\n",
        "            x, y, width, height, class_label = box\n",
        "            has_anchor = [False] * 3  # each scale should have one anchor\n",
        "\n",
        "            for anchor_idx in anchor_indices:\n",
        "              scale_idx = anchor_idx // self.num_anchors_per_scale # untuk mendapatkan kira kira bounding box ini ada di scale yang mana\n",
        "              anchor_on_scale = anchor_idx % self.num_anchors_per_scale\n",
        "\n",
        "              S = self.S[scale_idx]\n",
        "              i, j = int(S * y), int(S * x)  # which cell\n",
        "              anchor_taken = targets[scale_idx][anchor_on_scale, i, j, 0]\n",
        "              if not anchor_taken and not has_anchor[scale_idx]: #memproses atau menconvert x,y,w,h yang berdasarkan gambar scale nya menjadi berdasarkan grid dari setiap scale nya\n",
        "                targets[scale_idx][anchor_on_scale, i, j, 0] = 1\n",
        "                x_cell, y_cell = S * x - j, S * y - i  # both between [0,1]\n",
        "                width_cell, height_cell = (\n",
        "                    width * S,\n",
        "                    height * S,\n",
        "                )  # can be greater than 1 since it's relative to cell\n",
        "                box_coordinates = torch.tensor(\n",
        "                    [x_cell, y_cell, width_cell, height_cell]\n",
        "                )\n",
        "                targets[scale_idx][anchor_on_scale, i, j, 1:5] = box_coordinates\n",
        "                targets[scale_idx][anchor_on_scale, i, j, 5] = int(class_label)\n",
        "                has_anchor[scale_idx] = True\n",
        "\n",
        "              elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_thresh:\n",
        "                  targets[scale_idx][anchor_on_scale, i, j, 0] = -1  # ignore prediction\n",
        "\n",
        "\n",
        "        return image, tuple(targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MVHT8oYZVFfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23472111-8383-41cf-ef88-350c12d2e1c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3000\n"
          ]
        }
      ],
      "source": [
        "data = CocoPersonDataset(dataset)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I39DkoW8VOne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484b2a3f-1844-4203-cfe7-fd607771a623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-17dcd568b787>:74: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  iou_anchors = iou_width_height(torch.tensor(box[2:4]), self.anchors)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9.4492), tensor(18.8983), tensor(37.7967))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[0][1][0].max(), data[0][1][1].max(), data[0][1][2].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5PdGj0XUCB-"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d7s15DFQT9mF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\"\"\" \n",
        "Information about architecture config:\n",
        "Tuple is structured by (filters, kernel_size, stride) \n",
        "Every conv is a same convolution. \n",
        "List is structured by \"B\" indicating a residual block followed by the number of repeats\n",
        "\"S\" is for scale prediction block and computing the yolo loss\n",
        "\"U\" is for upsampling the feature map and concatenating with a previous layer\n",
        "\"\"\"\n",
        "config = [\n",
        "    (32, 3, 1),\n",
        "    (64, 3, 2),\n",
        "    [\"B\", 1],\n",
        "    (128, 3, 2),\n",
        "    [\"B\", 2],\n",
        "    (256, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (512, 3, 2),\n",
        "    [\"B\", 8],\n",
        "    (1024, 3, 2),\n",
        "    [\"B\", 4],  # To this point is Darknet-53\n",
        "    (512, 1, 1),\n",
        "    (1024, 3, 1),\n",
        "    \"S\",\n",
        "    (256, 1, 1),\n",
        "    \"U\",\n",
        "    (256, 1, 1),\n",
        "    (512, 3, 1),\n",
        "    \"S\",\n",
        "    (128, 1, 1),\n",
        "    \"U\",\n",
        "    (128, 1, 1),\n",
        "    (256, 3, 1),\n",
        "    \"S\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zMEHD0aFUymJ"
      },
      "outputs": [],
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\n",
        "    self.use_bn_act = bn_act\n",
        "    if bn_act:\n",
        "      self.bn = nn.BatchNorm2d(out_channels)\n",
        "      self.leaky = nn.LeakyReLU(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.use_bn_act:\n",
        "      return self.leaky(self.bn(self.conv(x)))\n",
        "    else:\n",
        "      return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mSlSybi7U0f1"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, channels, use_residual=True, num_repeats=1):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for repeat in range(num_repeats):\n",
        "      self.layers += [nn.Sequential(\n",
        "          CNNBlock(channels, channels//2, kernel_size=1),\n",
        "          CNNBlock(channels//2, channels, kernel_size=3, padding=1)\n",
        "      )]\n",
        "\n",
        "      self.use_residual = use_residual\n",
        "      self.num_repeats = num_repeats\n",
        "    \n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      if self.use_residual:\n",
        "        x = x + layer(x)\n",
        "      else:\n",
        "        x = layer(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6Ng2g0UrU106"
      },
      "outputs": [],
      "source": [
        "class ScalePrediction(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes):\n",
        "    super().__init__()\n",
        "    self.pred = nn.Sequential(\n",
        "        CNNBlock(in_channels, 2*in_channels, kernel_size=3, padding=1),\n",
        "        CNNBlock(2*in_channels, (num_classes+5)*3, bn_act=False, kernel_size=1)\n",
        "    )\n",
        "\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    # B, C=(3*(num_classes+5)), H, W -> B, 3, num_classes+5, 13, 13 -> B, 3, 13,13, num_classes+5\n",
        "    return self.pred(x).reshape(x.shape[0], 3, self.num_classes+5, x.shape[2], x.shape[3]).permute(0,1,3,4,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EyLrLKAgU3Sm"
      },
      "outputs": [],
      "source": [
        "class YOLOV3(nn.Module):\n",
        "  def __init__(self, in_channels=3, num_classes=20):\n",
        "    super().__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.in_channels = in_channels\n",
        "    self.layers = self._create_conv_layers()\n",
        "\n",
        "  def _create_conv_layers(self):\n",
        "    layers = nn.ModuleList()\n",
        "    in_channels = self.in_channels\n",
        "\n",
        "    for module in config:\n",
        "      if isinstance(module, tuple):\n",
        "        out_channels, kernel_size, stride = module\n",
        "        layers.append(CNNBlock(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding = 1 if kernel_size == 3 else 0))\n",
        "        in_channels = out_channels\n",
        "      elif isinstance(module, list):\n",
        "        num_repeats = module[1]\n",
        "        layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))\n",
        "      elif isinstance(module, str):\n",
        "        if module == \"S\":\n",
        "            layers += [\n",
        "                ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n",
        "                CNNBlock(in_channels, in_channels // 2, kernel_size=1),\n",
        "                ScalePrediction(in_channels // 2, num_classes=self.num_classes),\n",
        "            ]\n",
        "            in_channels = in_channels // 2\n",
        "\n",
        "        elif module == \"U\":\n",
        "            layers.append(nn.Upsample(scale_factor=2),)\n",
        "            in_channels = in_channels * 3\n",
        "    return layers\n",
        "\n",
        "  \n",
        "  def forward(self, x):\n",
        "    outputs = []  # for each scale\n",
        "    route_connections = [] # untuk menyimpan residual value yang akan di concat pada saat setelah upsampling\n",
        "    for layer in self.layers:\n",
        "        if isinstance(layer, ScalePrediction):\n",
        "            outputs.append(layer(x))\n",
        "            continue\n",
        "\n",
        "        x = layer(x)\n",
        "\n",
        "        if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n",
        "            route_connections.append(x)\n",
        "\n",
        "        elif isinstance(layer, nn.Upsample):\n",
        "            x = torch.cat([x, route_connections[-1]], dim=1)\n",
        "            route_connections.pop()\n",
        "\n",
        "    return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pJ5GnwtrU5TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875f98d1-b7b9-4228-a0a5-2f6d10a2136b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.Size([1, 3, 13, 13, 6]), torch.Size([1, 3, 26, 26, 6]), torch.Size([1, 3, 52, 52, 6])]\n"
          ]
        }
      ],
      "source": [
        "model = YOLOV3(3, 1) #RGB, 1 jumlah kelas\n",
        "\n",
        "dummy_input = torch.randn((1,3,416,416))\n",
        "out = model(dummy_input)\n",
        "print([ou.shape for ou in out])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDWZAPdXdRcO"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ieRzlVTTU9KT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of Yolo Loss Function similar to the one in Yolov3 paper,\n",
        "the difference from what I can tell is I use CrossEntropy for the classes\n",
        "instead of BinaryCrossEntropy.\n",
        "\"\"\"\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class YoloLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.entropy = nn.CrossEntropyLoss()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "        # Constants signifying how much to pay for each respective part of the loss\n",
        "        self.lambda_class = 1\n",
        "        self.lambda_noobj = 10\n",
        "        self.lambda_obj = 1\n",
        "        self.lambda_box = 10\n",
        "\n",
        "    def forward(self, predictions, target, anchors):\n",
        "        # Check where obj and noobj (we ignore if target == -1)\n",
        "        obj = target[..., 0] == 1  # in paper this is Iobj_i\n",
        "        noobj = target[..., 0] == 0  # in paper this is Inoobj_i\n",
        "\n",
        "        # ======================= #\n",
        "        #   FOR NO OBJECT LOSS    #\n",
        "        # ======================= #\n",
        "\n",
        "        no_object_loss = self.bce(\n",
        "            (predictions[..., 0:1][noobj]), (target[..., 0:1][noobj]),\n",
        "        )\n",
        "\n",
        "        # ==================== #\n",
        "        #   FOR OBJECT LOSS    #\n",
        "        # ==================== #\n",
        "\n",
        "        anchors = anchors.reshape(1, 3, 1, 1, 2)\n",
        "        box_preds = torch.cat([self.sigmoid(predictions[..., 1:3]), torch.exp(predictions[..., 3:5]) * anchors], dim=-1)\n",
        "        ious = intersection_over_union(box_preds[obj], target[..., 1:5][obj]).detach()\n",
        "        object_loss = self.mse(self.sigmoid(predictions[..., 0:1][obj]), ious * target[..., 0:1][obj])\n",
        "\n",
        "        # ======================== #\n",
        "        #   FOR BOX COORDINATES    #\n",
        "        # ======================== #\n",
        "\n",
        "        predictions[..., 1:3] = self.sigmoid(predictions[..., 1:3])  # x,y coordinates\n",
        "        target[..., 3:5] = torch.log(\n",
        "            (1e-16 + target[..., 3:5] / anchors)\n",
        "        )  # width, height coordinates\n",
        "        box_loss = self.mse(predictions[..., 1:5][obj], target[..., 1:5][obj])\n",
        "\n",
        "        # ================== #\n",
        "        #   FOR CLASS LOSS   #\n",
        "        # ================== #\n",
        "\n",
        "        class_loss = self.entropy(\n",
        "            (predictions[..., 5:][obj]), (target[..., 5][obj].long()),\n",
        "        )\n",
        "\n",
        "        #print(\"__________________________________\")\n",
        "        #print(self.lambda_box * box_loss)\n",
        "        #print(self.lambda_obj * object_loss)\n",
        "        #print(self.lambda_noobj * no_object_loss)\n",
        "        #print(self.lambda_class * class_loss)\n",
        "        #print(\"\\n\")\n",
        "\n",
        "        return (\n",
        "            self.lambda_box * box_loss\n",
        "            + self.lambda_obj * object_loss\n",
        "            + self.lambda_noobj * no_object_loss\n",
        "            + self.lambda_class * class_loss\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc2z_NSPhKcE"
      },
      "source": [
        "## Train Phase and Evaluation Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M3fnVn6kdSjD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def train_fn(model, dataloader, optimizer, device, loss_fn, scaler, scaled_anchors):\n",
        "  #do training and calculate training loss\n",
        "  loop = tqdm(dataloader, leave=True)\n",
        "  losses = []\n",
        "  for batch_idx, (x, y) in enumerate(loop):\n",
        "      x = x.to(device)\n",
        "      y0, y1, y2 = (\n",
        "          y[0].to(device),\n",
        "          y[1].to(device),\n",
        "          y[2].to(device),\n",
        "      )\n",
        "\n",
        "      with torch.cuda.amp.autocast():\n",
        "          out = model(x)\n",
        "          loss = (\n",
        "              loss_fn(out[0], y0, scaled_anchors[0])\n",
        "              + loss_fn(out[1], y1, scaled_anchors[1])\n",
        "              + loss_fn(out[2], y2, scaled_anchors[2])\n",
        "          )\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      optimizer.zero_grad()\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      # update progress bar\n",
        "      mean_loss = sum(losses) / len(losses)\n",
        "      loop.set_postfix(loss=mean_loss)\n",
        "\n",
        "def evaluate(model, dataloader, iou_threshold=0.5, anchors=ANCHORS, threshold=0.45, device=\"cpu\"):\n",
        "  #calculate mAP for the data evaluation, don't forget to run NMS first before do the mean Average Precision\n",
        "  all_pred_boxes, all_true_boxes = get_evaluation_bboxes(dataloader, model, iou_threshold, anchors, threshold, device=device)\n",
        "  mAP = mean_average_precision(all_pred_boxes, all_true_boxes, num_classes=1)\n",
        "  print(f\"mAP: {mAP}\")\n",
        "  model.train()\n",
        "\n",
        "def check_class_accuracy(model, dataloader, device, threshold):\n",
        "  model.eval()\n",
        "  tot_class_preds, correct_class = 0, 0\n",
        "  tot_noobj, correct_noobj = 0, 0\n",
        "  tot_obj, correct_obj = 0, 0\n",
        "\n",
        "  for idx, (x, y) in enumerate(tqdm(dataloader)):\n",
        "      x = x.to(device)\n",
        "      with torch.no_grad():\n",
        "          out = model(x)\n",
        "\n",
        "      for i in range(3):\n",
        "          y[i] = y[i].to(device)\n",
        "          obj = y[i][..., 0] == 1 # in paper this is Iobj_i\n",
        "          noobj = y[i][..., 0] == 0  # in paper this is Iobj_i\n",
        "\n",
        "          correct_class += torch.sum(\n",
        "              torch.argmax(out[i][..., 5:][obj], dim=-1) == y[i][..., 5][obj]\n",
        "          )\n",
        "          tot_class_preds += torch.sum(obj)\n",
        "\n",
        "          obj_preds = torch.sigmoid(out[i][..., 0]) > threshold\n",
        "          correct_obj += torch.sum(obj_preds[obj] == y[i][..., 0][obj])\n",
        "          tot_obj += torch.sum(obj)\n",
        "          correct_noobj += torch.sum(obj_preds[noobj] == y[i][..., 0][noobj])\n",
        "          tot_noobj += torch.sum(noobj)\n",
        "\n",
        "  print(f\"Class accuracy is: {(correct_class/(tot_class_preds+1e-16))*100:2f}%\")\n",
        "  print(f\"No obj accuracy is: {(correct_noobj/(tot_noobj+1e-16))*100:2f}%\")\n",
        "  print(f\"Obj accuracy is: {(correct_obj/(tot_obj+1e-16))*100:2f}%\")\n",
        "  model.train()\n",
        "\n",
        "def save_checkpoint(model, optimizer, filename=\"/content/drive/MyDrive/Colab Notebooks/my_yolov3_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    checkpoint = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    checkpoint = torch.load(checkpoint_file, map_location=config.DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    # If we don't do this then it will just have learning rate of old checkpoint\n",
        "    # and it will lead to many hours of debugging \\:\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8V0Qt7O_hr4L"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train():\n",
        "  #do initialization of model, loss, optimizer and do the training and evaluation based on how many epochs also save the model\n",
        "\n",
        "  #config\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  IMAGE_SIZE = 416\n",
        "  NUM_CLASSES = 1\n",
        "  LEARNING_RATE = 1e-5\n",
        "  WEIGHT_DECAY = 1e-4\n",
        "  NUM_EPOCHS = 51\n",
        "  CONF_THRESHOLD = 0.05\n",
        "  MAP_IOU_THRESH = 0.5\n",
        "  NMS_IOU_THRESH = 0.45\n",
        "\n",
        "  model = YOLOV3(num_classes=NUM_CLASSES).to(device) #RGB, 1 jumlah kelas\n",
        "  loss_fn = YoloLoss()\n",
        "  optimizer = optim.Adam(\n",
        "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "  )\n",
        "\n",
        "  scaler = torch.cuda.amp.GradScaler() #mempercepat dan memeperingan training 1.5 - 2x\n",
        "\n",
        "  S = [13, 26, 52]\n",
        "  scaled_anchors = (\n",
        "      torch.tensor(ANCHORS)\n",
        "      * torch.tensor(S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
        "  ).to(device)\n",
        "\n",
        "  train_dataset = CocoPersonDataset(dataset)\n",
        "  test_dataset = CocoPersonDataset(dataset_test)\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "  test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "  for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"epoch:{epoch}==>\")\n",
        "    #plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n",
        "    train_fn(model, train_loader, optimizer, device, loss_fn, scaler, scaled_anchors)\n",
        "\n",
        "    if epoch > 0 and epoch % 10 == 0:\n",
        "        evaluate(model, test_loader, iou_threshold=MAP_IOU_THRESH, anchors=ANCHORS, device=device)\n",
        "        save_checkpoint(model,optimizer)\n",
        "        model.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "iIHrMQxefCcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcc3e7e-eac2-4186-cabb-8975a9bbde64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:0==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.87it/s, loss=31.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  6.00it/s, loss=17.3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:2==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.03it/s, loss=13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:3==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.86it/s, loss=10.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:4==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:06<00:00,  5.91it/s, loss=9.28]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:5==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.05it/s, loss=8.16]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:6==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.97it/s, loss=7.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:7==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.98it/s, loss=6.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:8==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.01it/s, loss=6.18]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:9==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.88it/s, loss=5.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:10==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.03it/s, loss=5.38]\n",
            "100%|██████████| 125/125 [00:37<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP: 0.0\n",
            "=> Saving checkpoint\n",
            "epoch:11==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.86it/s, loss=5.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:12==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.88it/s, loss=4.78]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:13==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.86it/s, loss=4.47]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:14==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.01it/s, loss=4.34]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:15==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:09<00:00,  5.81it/s, loss=4.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:16==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.85it/s, loss=3.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:17==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.99it/s, loss=3.86]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:18==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.88it/s, loss=3.75]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:19==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.90it/s, loss=3.61]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:20==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.88it/s, loss=3.47]\n",
            "100%|██████████| 125/125 [00:36<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP: 0.0\n",
            "=> Saving checkpoint\n",
            "epoch:21==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:09<00:00,  5.80it/s, loss=3.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:22==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.82it/s, loss=3.32]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:23==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:09<00:00,  5.80it/s, loss=3.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:24==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:06<00:00,  5.94it/s, loss=3.17]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:25==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.82it/s, loss=3.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:26==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  6.00it/s, loss=3.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:27==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.88it/s, loss=2.99]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:28==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.87it/s, loss=2.92]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:29==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.02it/s, loss=2.89]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:30==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.84it/s, loss=2.83]\n",
            "100%|██████████| 125/125 [00:35<00:00,  3.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP: 0.0\n",
            "=> Saving checkpoint\n",
            "epoch:31==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:11<00:00,  5.71it/s, loss=2.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:32==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.04it/s, loss=2.71]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:33==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.90it/s, loss=2.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:34==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.02it/s, loss=2.67]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:35==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.02it/s, loss=2.62]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:36==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.96it/s, loss=2.59]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:37==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:06<00:00,  5.94it/s, loss=2.56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:38==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.02it/s, loss=2.51]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:39==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.89it/s, loss=2.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:40==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:07<00:00,  5.89it/s, loss=2.45]\n",
            "100%|██████████| 125/125 [00:35<00:00,  3.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP: 0.0020169212948530912\n",
            "=> Saving checkpoint\n",
            "epoch:41==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:10<00:00,  5.77it/s, loss=2.42]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:42==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:04<00:00,  6.02it/s, loss=2.36]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:43==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.83it/s, loss=2.35]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:44==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:06<00:00,  5.93it/s, loss=2.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:45==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:06<00:00,  5.92it/s, loss=2.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:46==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:08<00:00,  5.85it/s, loss=2.26]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:47==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:02<00:00,  6.10it/s, loss=2.24]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:48==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.99it/s, loss=2.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:49==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:05<00:00,  5.96it/s, loss=2.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:50==>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 750/750 [02:03<00:00,  6.08it/s, loss=2.17]\n",
            "100%|██████████| 125/125 [00:37<00:00,  3.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mAP: 0.005011811852455139\n",
            "=> Saving checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMGSZ = 416\n",
        "\n",
        "def preprocess(image):\n",
        "    transforms = A.Compose([\n",
        "                    A.Resize(height=IMGSZ, width=IMGSZ),\n",
        "                    A.Normalize(),\n",
        "                    ToTensorV2(),\n",
        "                ])\n",
        "    return transforms(image=image)[\"image\"]\n",
        "    \n",
        "def inference(model, x, device):\n",
        "    model.eval()\n",
        "    x = torch.unsqueeze(x, 0) #Neural Network B, C, H, Warning\n",
        "    x = x.to(device)\n",
        "    x = model(x)\n",
        "    return x\n",
        "    \n",
        "def postprocess(output, anchors, iou_threshold, threshold, device):\n",
        "    bboxes = []\n",
        "    for i in range(3):\n",
        "        S = prediction[i].shape[2] #ambil scale dari output predictions 13 atau 26 atau 52\n",
        "        anchor = torch.tensor([*anchors[i]]).to(device) * S\n",
        "        boxes_scale_i = cells_to_bboxes(\n",
        "            predictions[i], anchor, S=S, is_preds=True\n",
        "        )\n",
        "        for idx, (box) in enumerate(boxes_scale_i):\n",
        "            bboxes += box\n",
        "            \n",
        "    nms_boxes = non_max_suppression(\n",
        "                    bboxes,\n",
        "                    iou_threshold=iou_threshold,\n",
        "                    threshold=threshold,\n",
        "                    box_format=\"midpoint\",\n",
        "                )\n",
        "                \n",
        "    return nms_boxes"
      ],
      "metadata": {
        "id": "LEltZqVNbi38"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}